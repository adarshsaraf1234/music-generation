{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adarsh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Adarsh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Adarsh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Adarsh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Adarsh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Adarsh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Adarsh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Adarsh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Adarsh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Adarsh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Adarsh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Adarsh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import music21 as m\n",
    "import json\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Program Files/MuseScore 3/bin/MuseScore3.exe')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from music21 import *\n",
    "us = environment.UserSettings()\n",
    "for key in sorted(us.keys()):\n",
    "    key\n",
    "us['musicxmlPath'] = 'C:\\\\Program Files\\\\MuseScore 3\\\\bin\\\\MuseScore3.exe'\n",
    "us['musicxmlPath']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_path=\"C:\\\\Users\\\\Adarsh\\\\Desktop\\\\New folder\"\n",
    "acceptable_durations={0.25,\n",
    "                     0.5,\n",
    "                     0.75,\n",
    "                     1,\n",
    "                     1.5,\n",
    "                     2,\n",
    "                     3,\n",
    "                     4,6,8,18}\n",
    "SAVE_DIR=\"C:\\\\Users\\\\Adarsh\\\\Desktop\\\\dataset\"\n",
    "dataset_path=\"C:\\\\Users\\\\Adarsh\\\\Desktop\\\\dataset\"\n",
    "single_file_dataset=\"File dataset\"\n",
    "sequence_length=256\n",
    "mapping_path=\"mapping.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midi_songs(path):\n",
    "    songs=[]\n",
    "    for path,subdirs,files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file[-3:]==\"mid\":\n",
    "                song=m.converter.parse(os.path.join(path,file))\n",
    "                songs.append(song)\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_acceptable_durations(song, acceptable_durations):\n",
    "    \"\"\"Boolean routine that returns True if piece has all acceptable duration, False otherwise.\n",
    "    :param song (m21 stream):\n",
    "    :param acceptable_durations (list): List of acceptable duration in quarter length\n",
    "    :return (bool):\n",
    "    \"\"\"\n",
    "    for note in song.flat.notesAndRests:\n",
    "        if note.duration.quarterLength not in acceptable_durations:\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_song(song, time_step=0.5):\n",
    "   \n",
    "    encoded_song = []\n",
    "\n",
    "    for event in song.flat.notesAndRests:\n",
    "        global symbol        \n",
    "        if isinstance(event, m.note.Note):\n",
    "            symbol = event.pitch.midi        \n",
    "        elif isinstance(event, m.note.Rest):\n",
    "            symbol = \"r\"       \n",
    "        steps = int(event.duration.quarterLength / time_step)\n",
    "        for step in range(steps):            \n",
    "            if step == 0:\n",
    "                encoded_song.append(symbol)\n",
    "            else:\n",
    "                encoded_song.append(\"_\")    \n",
    "    encoded_song = \" \".join(map(str, encoded_song))\n",
    "\n",
    "    return encoded_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path):\n",
    "    songs=load_midi_songs(midi_path)\n",
    "    print(f\"loaded {len(songs)}\")\n",
    "    for i,song in enumerate(songs):\n",
    "        if not has_acceptable_durations(song, acceptable_durations):\n",
    "            continue\n",
    "        #song = transpose(song)\n",
    "        encoded_song = encode_song(song)\n",
    "        save_path = os.path.join(SAVE_DIR, str(i))\n",
    "        with open(save_path, \"w\") as fp:\n",
    "            fp.write(encoded_song)\n",
    "                \n",
    "           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file_path):\n",
    "    with open(file_path,\"r\") as fp:\n",
    "        song=fp.read()\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_path,file_dataset_path,sequence_length):\n",
    "    new_song_deli=\"/ \"*sequence_length\n",
    "    songs=\"\"\n",
    "    for path,_,files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            file_path=os.path.join(path,file)\n",
    "            song=load(file_path)\n",
    "            songs=songs+song+\" \"+new_song_deli\n",
    "    songs=songs[:-1]\n",
    "    with open(file_dataset_path,\"w\") as fp:\n",
    "        fp.write(songs)\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapping(songs,mapping_path):\n",
    "    mappings={}\n",
    "    songs=songs.split()\n",
    "    vocabulary=list(set(songs))\n",
    "    for i,symbol in enumerate(vocabulary):\n",
    "        mappings[symbol]=i\n",
    "        with open(mapping_path,\"w\") as fp:\n",
    "            json.dump(mappings,fp,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_songs_to_int(songs):\n",
    "    int_songs=[]\n",
    "    with open(mapping_path,\"r\") as fp:\n",
    "        mappings=json.load(fp)\n",
    "    songs=songs.split()\n",
    "    for symbol in songs:\n",
    "        int_songs.append(mappings[symbol])\n",
    "    return int_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_training_sequences(sequence_length):\n",
    "    songs=load(single_file_dataset)\n",
    "    int_songs=convert_songs_to_int(songs)\n",
    "    inputs=[]\n",
    "    targets=[]\n",
    "    num_sequences=len(int_songs)-sequence_length\n",
    "    for i in range(num_sequences):\n",
    "        inputs.append(int_songs[i:i+sequence_length])\n",
    "        targets.append(int_songs[i+sequence_length])\n",
    "    vocabulary_size=len(set(int_songs))\n",
    "    inputs=keras.utils.to_categorical(inputs,num_classes=vocabulary_size)\n",
    "    targets=np.array(targets)\n",
    "    return inputs,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 14\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "   \n",
    "    preprocess(midi_path)\n",
    "    songs=create_dataset(dataset_path,single_file_dataset,sequence_length)    \n",
    "    create_mapping(songs,mapping_path)\n",
    "    inputs ,targets = generating_training_sequences(sequence_length)\n",
    "    \n",
    "    #song.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1805, 256, 20)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1805,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from preprocess import generating_training_sequences, sequence_length\n",
    "import tensorflow.keras as keras\n",
    "OUTPUT_UNITS=20\n",
    "LOSS=\"sparse_categorical_crossentropy\"\n",
    "LEARNING_RATE=0.001\n",
    "NUM_UNITS=[256,256]\n",
    "EPOCHS=90\n",
    "BATCH_SIZE=256\n",
    "save_model_path=\"model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(output_units=OUTPUT_UNITS,num_units=NUM_UNITS,loss=LOSS,learning_rate=LEARNING_RATE):\n",
    "    input=keras.layers.Input(shape=[None,output_units])\n",
    "    x=keras.layers.LSTM(num_units[0])(input)\n",
    "    x=keras.layers.Dropout(0.2)(x)\n",
    "   \n",
    "    \n",
    "    output=keras.layers.Dense(output_units,activation=\"softmax\")(x)\n",
    "    model=keras.Model(input,output)\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(output_units,num_units,loss,learning_rate):\n",
    "    inputs,targets=generating_training_sequences(sequence_length)\n",
    "    model=build_model(output_units,num_units,loss,learning_rate)\n",
    "    model.fit(inputs,targets,epochs=EPOCHS,batch_size=BATCH_SIZE)\n",
    "    model.save(save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None, 20)]        0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               283648    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 288,788\n",
      "Trainable params: 288,788\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "1805/1805 [==============================] - 32s 18ms/sample - loss: 2.4002 - acc: 0.6737\n",
      "Epoch 2/90\n",
      "1805/1805 [==============================] - 35s 20ms/sample - loss: 0.9887 - acc: 0.7789\n",
      "Epoch 3/90\n",
      "1805/1805 [==============================] - 39s 22ms/sample - loss: 0.8482 - acc: 0.7812\n",
      "Epoch 4/90\n",
      "1805/1805 [==============================] - 41s 23ms/sample - loss: 0.7751 - acc: 0.8150\n",
      "Epoch 5/90\n",
      "1805/1805 [==============================] - 45s 25ms/sample - loss: 0.7103 - acc: 0.8288\n",
      "Epoch 6/90\n",
      "1805/1805 [==============================] - 48s 27ms/sample - loss: 0.6736 - acc: 0.8427\n",
      "Epoch 7/90\n",
      "1805/1805 [==============================] - 49s 27ms/sample - loss: 0.6500 - acc: 0.8438\n",
      "Epoch 8/90\n",
      "1805/1805 [==============================] - 54s 30ms/sample - loss: 0.6309 - acc: 0.8454\n",
      "Epoch 9/90\n",
      "1805/1805 [==============================] - 57s 31ms/sample - loss: 0.6159 - acc: 0.8465\n",
      "Epoch 10/90\n",
      "1805/1805 [==============================] - 59s 33ms/sample - loss: 0.6062 - acc: 0.8504\n",
      "Epoch 11/90\n",
      "1805/1805 [==============================] - 63s 35ms/sample - loss: 0.6052 - acc: 0.8510\n",
      "Epoch 12/90\n",
      "1805/1805 [==============================] - 66s 37ms/sample - loss: 0.6063 - acc: 0.8488\n",
      "Epoch 13/90\n",
      "1805/1805 [==============================] - 68s 38ms/sample - loss: 0.5943 - acc: 0.8482\n",
      "Epoch 14/90\n",
      "1805/1805 [==============================] - 69s 38ms/sample - loss: 0.5864 - acc: 0.8515\n",
      "Epoch 15/90\n",
      "1805/1805 [==============================] - 72s 40ms/sample - loss: 0.5812 - acc: 0.8515\n",
      "Epoch 16/90\n",
      "1805/1805 [==============================] - 73s 40ms/sample - loss: 0.5785 - acc: 0.8548\n",
      "Epoch 17/90\n",
      "1805/1805 [==============================] - 75s 41ms/sample - loss: 0.5820 - acc: 0.8565\n",
      "Epoch 18/90\n",
      "1805/1805 [==============================] - 75s 42ms/sample - loss: 0.5883 - acc: 0.8521\n",
      "Epoch 19/90\n",
      "1805/1805 [==============================] - 77s 43ms/sample - loss: 0.5871 - acc: 0.8526\n",
      "Epoch 20/90\n",
      "1805/1805 [==============================] - 77s 42ms/sample - loss: 0.5675 - acc: 0.8537\n",
      "Epoch 21/90\n",
      "1805/1805 [==============================] - 81s 45ms/sample - loss: 0.5563 - acc: 0.8543\n",
      "Epoch 22/90\n",
      "1536/1805 [========================>.....] - ETA: 12s - loss: 0.5386 - acc: 0.8581"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-3dc74b750278>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOUTPUT_UNITS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_UNITS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLOSS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-ecb02cdd4c4e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(output_units, num_units, loss, learning_rate)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerating_training_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_units\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_model_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__== \"__main__\":\n",
    "    train(output_units=OUTPUT_UNITS,num_units=NUM_UNITS,loss=LOSS,learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class melodygenerator:\n",
    "    def __init__(self,model_path=\"model.h5\"):\n",
    "        self.model_path=model_path\n",
    "        self.model=keras.models.load_model(model_path)\n",
    "        with open(mapping_path,\"r\") as fp :\n",
    "            self.mappings=json.load(fp)\n",
    "        self._start_symbols=[\"/\"]*sequence_length\n",
    "    \n",
    "      \n",
    "    def generate_melody(self,seed,num_steps,max_sequence_length,temperature):\n",
    "        seed=seed.split()\n",
    "        melody=seed\n",
    "        seed=self._start_symbols+seed\n",
    "        seed=[self.mappings[symbol] for symbol in seed]\n",
    "        for _ in range(num_steps):\n",
    "            seed = seed[-max_sequence_length:]\n",
    "            onehot_seed=keras.utils.to_categorical(seed,num_classes=len(self.mappings))\n",
    "            onehot_seed=onehot_seed[np.newaxis,...]\n",
    "            probabilities = self.model.predict(onehot_seed)[0]\n",
    "            output_int = self._sample_with_temperature(probabilities, temperature)\n",
    "            seed.append(output_int)\n",
    "            output_symbol = [k for k, v in self.mappings.items() if v == output_int][0]\n",
    "            if output_symbol == \"/\":\n",
    "                break\n",
    "\n",
    "            # update melody\n",
    "            melody.append(output_symbol)\n",
    "\n",
    "        return melody\n",
    "    def _sample_with_temperature(self, probabilites, temperature):\n",
    "        \n",
    "        predictions = np.log(probabilites) / temperature\n",
    "        probabilites = np.exp(predictions) / np.sum(np.exp(predictions))\n",
    "\n",
    "        choices = range(len(probabilites)) # [0, 1, 2, 3]\n",
    "        index = np.random.choice(choices, p=probabilites)\n",
    "\n",
    "        return index\n",
    "    def save_melody(self, melody, step_duration=0.25, format=\"midi\", file_name=\"mel.mid\"):\n",
    "     \n",
    "        # create a music21 stream\n",
    "        stream = m.stream.Stream()\n",
    "\n",
    "        start_symbol = None\n",
    "        step_counter = 1\n",
    "\n",
    "        # parse all the symbols in the melody and create note/rest objects\n",
    "        for i, symbol in enumerate(melody):\n",
    "\n",
    "            # handle case in which we have a note/rest\n",
    "            if symbol != \"_\" or i + 1 == len(melody):\n",
    "\n",
    "                # ensure we're dealing with note/rest beyond the first one\n",
    "                if start_symbol is not None:\n",
    "\n",
    "                    quarter_length_duration = step_duration * step_counter # 0.25 * 4 = 1\n",
    "\n",
    "                    # handle rest\n",
    "                    if start_symbol == \"r\":\n",
    "                        m21_event = m.note.Rest(quarterLength=quarter_length_duration)\n",
    "\n",
    "                    # handle note\n",
    "                    else:\n",
    "                        m21_event = m.note.Note(int(start_symbol), quarterLength=quarter_length_duration)\n",
    "\n",
    "                    stream.append(m21_event)\n",
    "\n",
    "                    # reset the step counter\n",
    "                    step_counter = 1\n",
    "\n",
    "                start_symbol = symbol\n",
    "\n",
    "            # handle case in which we have a prolongation sign \"_\"\n",
    "            else:\n",
    "                step_counter += 1\n",
    "\n",
    "        # write the m21 stream to a midi file\n",
    "        stream.write(format, file_name)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['67', '_', '_', '_', '_', '_', '65', '_', '64', '_', '62', '_', '60', '_', '_', '_', '72', '_', '72', '_', '72', '_', '72', '_', '72', '_', '69', '_', '_', '_', '_', '_', 'r', '_', 'r', '_', '72', '_', '72', '_', '72', '_', '74', '_', '_', '_']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    mg = melodygenerator()\n",
    "    seed = \"67 _ 67 _ 67 _ _ 65 64 _ 64 _ 64 _ _\"\n",
    "    seed2 = \"67 _ _ _ _ _ 65 _ 64 _ 62 _ 60 _ _ _\"\n",
    "    melody = mg.generate_melody(seed2, 2000, sequence_length, 0.1)\n",
    "    print(melody)\n",
    "    mg.save_melody(melody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
